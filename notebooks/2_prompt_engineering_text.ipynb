{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet openai\n",
    "# !pip install --quiet python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aeb6fd",
   "metadata": {},
   "source": [
    "# Setting up configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5725825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'), base_url='https://api.openai.com/v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c4320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_get_response(prompt):\n",
    "    \"\"\"\n",
    "    Function to get a response from the OpenAI API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model = \"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5fe1177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of France\"\n",
    "response = llm_get_response(prompt)\n",
    "if response:\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07be280",
   "metadata": {},
   "source": [
    "# Prompt Engineering Patterns & Templates\n",
    "This notebook demonstrates various prompt engineering techniques using the theme:\n",
    "> **Tell me more about generative AI**\n",
    "\n",
    "We'll cover basic prompts, zero-shot, one-shot, few-shot, chain-of-thought, ReAct, and advanced techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609124d",
   "metadata": {},
   "source": [
    "## 1. Basic Prompt\n",
    "A straightforward instruction to elicit information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e06945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Generative AI refers to a class of artificial intelligence techniques specifically designed to create new content. This content can be in the form of text, images, music, code, or even more complex structures. The term \"generative\" is used because these models generate new data based on patterns they have learned from existing data.\n",
      "\n",
      "Here are some key concepts and components of generative AI:\n",
      "\n",
      "1. **Generative Models:** These are the backbone of generative AI. Common types include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models like GPT (Generative Pre-trained Transformer).\n",
      "\n",
      "   - **Generative Adversarial Networks (GANs):** GANs consist of two networks—a generator and a discriminator—competing against each other. The generator creates data, while the discriminator evaluates its authenticity. Through this adversarial process, GANs can produce highly realistic data, particularly images.\n",
      "\n",
      "   - **Variational Autoencoders (VAEs):** VAEs work by encoding input data into a compressed format and then decoding it back to its original form. This process helps them learn to generate new, similar data from the compressed representation.\n",
      "\n",
      "   - **Transformers and GPT:** These models, particularly the GPT series (like GPT-3 and GPT-4), leverage large-scale neural networks and are trained on vast amounts of text data. They excel at natural language processing tasks and can generate coherent and contextually relevant text.\n",
      "\n",
      "2. **Applications:**\n",
      "   - **Text Generation:** Models like GPT-3 and GPT-4 can write essays, generate code, create chatbots, and more.\n",
      "   - **Image Synthesis:** GANs are used to create photorealistic images, deepfakes, and artworks.\n",
      "   - **Music and Audio:** Generative AI can compose music, create sound effects, and even mimic specific musical styles.\n",
      "   - **Code Generation:** AI models can write and suggest code snippets, aiding software development.\n",
      "   - **Medical Imaging:** Generative models can assist in generating synthetic medical images for research and training, reducing the need for large datasets.\n",
      "\n",
      "3. **Ethical Considerations:** The ability of generative AI to produce realistic content raises concerns such as plagiarism, the creation of deepfakes, and misinformation. This necessitates ongoing ethical guidelines and robust AI policy frameworks.\n",
      "\n",
      "4. **Future Developments:** As AI research progresses, we anticipate more sophisticated generative models with improved capabilities, better handling of context, and the ability to create more seamless and integrated AI solutions across various fields.\n",
      "\n",
      "Generative AI is a powerful tool that continues to evolve, offering incredible possibilities for creativity and innovation, while also presenting challenges in ensuring its responsible use.\n"
     ]
    }
   ],
   "source": [
    "basic_prompt = \"Tell me more about generative AI.\"\n",
    "\n",
    "response = llm_get_response(basic_prompt)\n",
    "if response:\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146fc0df",
   "metadata": {},
   "source": [
    "## 2. Zero-Shot Prompt\n",
    "Providing context or role without examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = (\n",
    "    \"You are an expert in AI. \"  \n",
    "    \"Answer the following question concisely: 'Tell me more about generative AI.'\"\n",
    ")\n",
    "\n",
    "response = llm_get_response(zero_shot_prompt)\n",
    "if response:\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a25ad4",
   "metadata": {},
   "source": [
    "## 3. One-Shot Prompt\n",
    "Including a single example to guide the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43281076",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_prompt = (\n",
    "    \"Example:\\n\"  \n",
    "    \"Q: What is language modeling?\\n\"\n",
    "    \"A: Language modeling is the task of predicting the next word in a sequence...\\n\\n\"\n",
    "    \"Now answer this:\\n\"\n",
    "    \"Q: Tell me more about generative AI.\\n\"\n",
    "    \"A:\"\n",
    ")\n",
    "\n",
    "response = llm_get_response(one_shot_prompt)\n",
    "if response:\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5358c0",
   "metadata": {},
   "source": [
    "## 4. Few-Shot Prompt\n",
    "Providing multiple examples to improve consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = (\n",
    "    \"Example 1:\\n\"\n",
    "    \"Q: What is reinforcement learning?\\n\"\n",
    "    \"A: Reinforcement learning is...\\n\\n\"\n",
    "    \"Example 2:\\n\"\n",
    "    \"Q: Define transfer learning.\\n\"\n",
    "    \"A: Transfer learning refers to...\\n\\n\"\n",
    "    \"Now answer:\\n\"\n",
    "    \"Q: Tell me more about generative AI.\\n\"\n",
    "    \"A:\"\n",
    ")\n",
    "\n",
    "response = llm_get_response(few_shot_prompt)\n",
    "if response:\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27e488",
   "metadata": {},
   "source": [
    "## 5. Chain-of-Thought Prompt\n",
    "Encourage the model to show its reasoning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe034be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prompt = (\n",
    "    \"Explain step by step how generative AI models work. \"\n",
    "    \"Then summarize the key points.\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "response = llm_get_response(cot_prompt)\n",
    "if response:\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1903c9",
   "metadata": {},
   "source": [
    "## 6. ReAct Prompt\n",
    "Combining reasoning and actions (e.g., API calls, tool use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eddb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt = (\n",
    "    \"You are an AI assistant. Use the following tools: [search(query), calculate(expression)].\\n\"\n",
    "    \"When asked 'Tell me more about generative AI', think step-by-step and if needed, call search.\\n\"\n",
    "    \"Thought: What is generative AI?\\n\"\n",
    "    \"Action: search('generative AI definition')\\n\"\n",
    "    \"Observation: ... results ...\\n\"\n",
    "    \"Final Answer:\"\n",
    ")\n",
    "\n",
    "response = llm_get_response(react_prompt)\n",
    "if response:\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea0baf",
   "metadata": {},
   "source": [
    "## 7. Advanced Prompting Techniques\n",
    "- **Self-Consistency**: sample multiple reasoning paths and pick the most consistent answer.\n",
    "- **Tree of Thoughts**: explore multiple reasoning branches.\n",
    "- **Dynamic Prompting**: adapt prompt based on intermediate responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75205b31",
   "metadata": {},
   "source": [
    "### Self-Consistency Sampling\n",
    "Rather than taking a single reasoning path, you sample multiple chain-of-thought generations and then aggregate or vote on the most consistent answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5eff6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Consistency Answer:\n",
      " Generative AI refers to machine learning models that can create new content, such as text, images, or music, by learning patterns from existing data. It's powered by models like GANs, VAEs, and transformers. Applications span from creative to functional uses, including text generation, art creation, and music composition, though they raise ethical and quality concerns. Generative AI continues to evolve, promising to reshape various industries.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def self_consistency(prompt: str, samples: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Ask the model to “think” step-by-step multiple times, then pick\n",
    "    the most frequent final answer.\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    for i in range(samples):\n",
    "        # we nudge the model to include reasoning + final answer\n",
    "        full_prompt = (\n",
    "            \"Explain step by step, then give a concise answer.\\n\"\n",
    "            f\"Question: {prompt}\\nAnswer:\"\n",
    "        )\n",
    "        resp = llm_get_response(full_prompt)\n",
    "        # assume the last line is the short answer\n",
    "        answer = resp.strip().splitlines()[-1]\n",
    "        responses.append(answer)\n",
    "    # majority vote\n",
    "    most_common = Counter(responses).most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"Tell me more about generative AI.\"\n",
    "    consensus = self_consistency(question, samples=7)\n",
    "    print(\"Self-Consistency Answer:\\n\", consensus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d56daf3",
   "metadata": {},
   "source": [
    "### Tree of Thoughts\n",
    "You structure a tree of intermediate “thoughts” (hypotheses), explore each branch, then select the best path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60fbea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tree-of-Thoughts Answer:\n",
      " Generative AI refers to a category of artificial intelligence systems that are designed to generate data or content that resembles human-created media. These systems can produce text, images, music, and other forms of media by learning patterns and structures from existing datasets and then using these patterns to create new, similar outputs.\n",
      "\n",
      "One of the most prominent techniques used in generative AI is the transformer architecture. Transformer models, which include well-known instances such as OpenAI's GPT (Generative Pre-trained Transformer), are built on the concept of attention mechanisms. These mechanisms allow models to weigh the importance of different words (or other elements) when generating new content, thus enabling them to understand and create nuanced, contextually-relevant outputs.\n",
      "\n",
      "Transformers have revolutionized generative AI by allowing for massively parallel processing and an ability to capture long-range dependencies in data, making them particularly effective in natural language processing tasks such as machine translation, text summarization, and conversational agents. This architecture has also been adapted for various other generative tasks beyond text, contributing significantly to advancements in image generation and music synthesis.\n",
      "\n",
      "Overall, generative AI leverages complex models like transformers to produce innovative and high-quality content, greatly expanding the capabilities of AI in creative and functional applications.\n"
     ]
    }
   ],
   "source": [
    "def tree_of_thoughts(root_prompt: str, branches: list[list[str]]) -> str:\n",
    "    \"\"\"\n",
    "    branches: a list of thought-lists, e.g.\n",
    "      [\n",
    "        [\"Define generative AI\", \"Explain core architectures\"],\n",
    "        [\"List use-cases\", \"Discuss ethical issues\"]\n",
    "      ]\n",
    "    \"\"\"\n",
    "    best_answer = None\n",
    "    best_score = -1.0  # you could use a model-provided score or heuristic\n",
    "    for thought_path in branches:\n",
    "        # build a multi-step prompt\n",
    "        prefix = \"\\n\".join(f\"Thought: {t}\" for t in thought_path)\n",
    "        full_prompt = f\"{prefix}\\nQuestion: {root_prompt}\\nAnswer:\"\n",
    "        resp = llm_get_response(full_prompt)\n",
    "\n",
    "        # (Optional) ask model to score its own answer\n",
    "        score_prompt = (\n",
    "            f\"Rate the following answer 0–1 for correctness and completeness:\\n\\n{resp}\\n\\nScore:\"\n",
    "        )\n",
    "        score_resp = llm_get_response(score_prompt)\n",
    "        try:\n",
    "            score = float(score_resp.strip())\n",
    "        except:\n",
    "            score = 0.0\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_answer = resp\n",
    "\n",
    "    return best_answer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"Tell me more about generative AI.\"\n",
    "    paths = [\n",
    "        [\"Define generative AI\", \"Explain transformer architectures\"],\n",
    "        [\"Describe common applications\", \"Highlight recent advances\"]\n",
    "    ]\n",
    "    best = tree_of_thoughts(question, paths)\n",
    "    print(\"Best Tree-of-Thoughts Answer:\\n\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd137a3",
   "metadata": {},
   "source": [
    "### Dynamic Prompting\n",
    "You iteratively adjust the prompt based on the model’s intermediate output (e.g., ask follow-up clarifications or refine instructions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "745c4329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 response:\n",
      "Generative AI refers to a subset of artificial intelligence that focuses on creating new content or data, often resembling or inspired by existing datasets. Unlike traditional AI systems that focus on analyzing or classifying existing data, generative AI models are designed to generate new examples. Here are some key aspects and applications of generative AI:\n",
      "\n",
      "1. **Underlying Technologies:**\n",
      "\n",
      "   - **Generative Adversarial Networks (GANs):** Introduced by Ian Goodfellow in 2014, GANs consist of two neural networks—a generator and a discriminator—that are trained simultaneously. The generator creates samples, and the discriminator evaluates them against real data. The generator improves its output to fool the discriminator over time.\n",
      "\n",
      "   - **Variational Autoencoders (VAEs):** VAEs are used for generating new data by learning a compressed latent representation of data which enables generation of new samples.\n",
      "\n",
      "   - **Transformers:** Originally designed for tasks like language translation, transformers (particularly the encoder-decoder architecture) are used in many generative tasks, including language generation and content creation. Models like OpenAI’s GPT and DALL-E are based on this architecture.\n",
      "\n",
      "2. **Applications:**\n",
      "\n",
      "   - **Text Generation:** Models like GPT-3 and GPT-4 from OpenAI can generate coherent and contextually relevant text. These models are used for chatbots, writing assistance, story generation, and more.\n",
      "\n",
      "   - **Image Creation:** Tools like DALL-E, Midjourney, and Stable Diffusion generate images from textual descriptions, allowing the creation of artwork, conceptual designs, or product images.\n",
      "\n",
      "   - **Music and Audio:** Generative models can compose music or generate realistic human-like voices. Applications include composing new music tracks or providing voiceovers.\n",
      "\n",
      "   - **Video and Animation:** AI can be used to generate video content or enhance existing footage. This includes deepfakes or creating digital humans for animations.\n",
      "\n",
      "   - **3D Model Generation:** AI can assist in creating 3D models for video games or simulations from descriptions or inputs.\n",
      "\n",
      "3. **Challenges and Considerations:**\n",
      "\n",
      "   - **Ethical Concerns:** Generative AI raises ethical questions, such as the potential for misuse in creating deepfakes or generating misleading content.\n",
      "\n",
      "   - **Bias and Fairness:** Generative models can inherit biases present in their training data, leading to biased outputs.\n",
      "\n",
      "   - **Copyright and Ownership:** There are ongoing debates about the ownership of AI-generated content, especially concerning models trained on copyrighted data.\n",
      "\n",
      "4. **Future Directions:**\n",
      "\n",
      "   - **Improved Control:** Researchers are focusing on making generative models more controllable, allowing users to specify more detailed attributes of generated content.\n",
      "\n",
      "   - **Creative Collaboration:** Generative AI is being used as a tool for artists, writers, and designers to collaborate with AI systems to extend their creative capabilities.\n",
      "\n",
      "Generative AI continues to advance rapidly, opening up exciting possibilities and posing new challenges across a range of industries and disciplines.\n",
      "\n",
      "Step 1 response:\n",
      "Implementing generative AI in production environments presents a unique set of challenges that organizations need to navigate. Here are some key challenges:\n",
      "\n",
      "1. **Scalability and Performance:**\n",
      "   - **Resource Intensive:** Generative AI models, especially large models like GPT-3 or DALL-E, require significant computational resources. This can make scaling such systems in production costly and complex.\n",
      "   - **Latency:** Real-time applications need low-latency responses, which can be challenging given the computational demands of these models.\n",
      "\n",
      "2. **Ethical and Social Implications:**\n",
      "   - **Content Misuse:** There's a risk of using generative AI to produce harmful content, such as deepfakes or misinformation. Organizations need robust policies to mitigate these risks.\n",
      "   - **Bias:** If models are trained on biased datasets, they can produce biased outputs, which can lead to unfair or discriminatory results in applications.\n",
      "\n",
      "3. **Quality Control:**\n",
      "   - **Output Consistency:** Ensuring the quality and reliability of AI-generated content can be challenging, as models might produce varying results under similar conditions. This unpredictability needs to be managed, especially in critical applications.\n",
      "   - **Human Oversight:** Balancing AI autonomy with human oversight is crucial to ensure that outputs are appropriate and aligned with standards.\n",
      "\n",
      "4. **Data Privacy and Security:**\n",
      "   - **Training Data Requirements:** Generative models often require access to large amounts of data, which can raise privacy concerns, especially if the data includes sensitive or proprietary information.\n",
      "   - **Security Risks:** AI systems can be vulnerable to adversarial attacks, where input is deliberately crafted to deceive the model.\n",
      "\n",
      "5. **Legal and Intellectual Property Challenges:**\n",
      "   - **Copyright and Licensing:** The use of copyrighted data for training and the ownership of AI-generated content are complex legal issues that need careful consideration.\n",
      "   - **Regulatory Compliance:** Organizations must ensure generative AI applications comply with industry regulations and standards, which can be a moving target as laws evolve.\n",
      "\n",
      "6. **User Experience and Adoption:**\n",
      "   - **Trust and Transparency:** Building user trust in AI-generated content is crucial. Users need transparency about how content is generated and the limitations of the technology.\n",
      "   - **Integration With Existing Systems:** Seamlessly integrating generative AI into existing workflows and systems can be technically challenging.\n",
      "\n",
      "7. **Ethical Considerations in Implementation:**\n",
      "   - **Accountability:** Determining who is accountable for AI outputs is essential, particularly when harm is caused by these outputs.\n",
      "   - **Cultural Sensitivity:** Ensuring that generated content is culturally sensitive and does not inadvertently offend or misrepresent groups is critical.\n",
      "\n",
      "Addressing these challenges requires a multidisciplinary approach, involving not just technical experts, but also ethicists, legal professionals, and domain experts to ensure responsible and effective deployment of generative AI in production settings.\n",
      "\n",
      "Dynamic Prompting Final Answer:\n",
      " Certainly! Here's a summarized bulleted list of the key challenges in implementing generative AI in production environments:\n",
      "\n",
      "- **Scalability and Performance:**\n",
      "  - Resource-intensive nature of large models\n",
      "  - Latency issues in real-time applications\n",
      "\n",
      "- **Ethical and Social Implications:**\n",
      "  - Risk of content misuse (e.g., deepfakes, misinformation)\n",
      "  - Bias in output due to biased training data\n",
      "\n",
      "- **Quality Control:**\n",
      "  - Inconsistency in AI-generated outputs\n",
      "  - Need for human oversight to maintain standards\n",
      "\n",
      "- **Data Privacy and Security:**\n",
      "  - Privacy concerns with large training data requirements\n",
      "  - Vulnerability to adversarial attacks\n",
      "\n",
      "- **Legal and Intellectual Property Challenges:**\n",
      "  - Complexities of copyright and licensing issues\n",
      "  - Compliance with evolving regulations\n",
      "\n",
      "- **User Experience and Adoption:**\n",
      "  - Building trust and transparency with users\n",
      "  - Challenges in integrating AI with existing systems\n",
      "\n",
      "- **Ethical Considerations in Implementation:**\n",
      "  - Determining accountability for AI outputs\n",
      "  - Ensuring cultural sensitivity in generated content\n",
      "\n",
      "Addressing these challenges requires a collaborative approach involving technical experts, ethicists, legal professionals, and domain experts.\n"
     ]
    }
   ],
   "source": [
    "def dynamic_prompting(initial: str, feedback_steps: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    1. Send an initial prompt.\n",
    "    2. Analyze the response; ask a targeted follow-up.\n",
    "    3. Incorporate feedback and repeat.\n",
    "    \"\"\"\n",
    "    prompt = initial\n",
    "    for step in range(feedback_steps):\n",
    "        resp = llm_get_response(prompt)\n",
    "        print(f\"Step {step} response:\\n{resp}\\n\")\n",
    "\n",
    "        # Generate a follow-up instruction\n",
    "        followup = (\n",
    "            \"Based on the previous answer, please elaborate specifically on \"\n",
    "            \"the key challenges of implementing generative AI in production.\"\n",
    "        ) if step == 0 else (\n",
    "            \"Great—now summarize your points in a bulleted list.\"\n",
    "        )\n",
    "\n",
    "        # Build new prompt with context\n",
    "        prompt = (\n",
    "            f\"{resp}\\n\\n\"\n",
    "            f\"### Follow-up:\\n{followup}\\nAnswer:\"\n",
    "        )\n",
    "\n",
    "    # final response\n",
    "    final = llm_get_response(prompt)\n",
    "    return final\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = \"Tell me more about generative AI.\"\n",
    "    result = dynamic_prompting(start, feedback_steps=2)\n",
    "    print(\"Dynamic Prompting Final Answer:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7332eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roleready",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
